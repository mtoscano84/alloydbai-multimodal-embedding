{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requistes"
      ],
      "metadata": {
        "id": "BXhD5BzaVBPA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcTRSVw7TfbD"
      },
      "source": [
        "Install the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGO9Ne6CTfbF"
      },
      "outputs": [],
      "source": [
        "!pip install psycopg2\n",
        "!pip install matplotlib\n",
        "!pip install google-cloud-storage\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr0BeNWJTfbG"
      },
      "source": [
        "Define your project ID, location, and bucket name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvR6YIj_TfbG"
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"[your-location]\"  # @param {type:\"string\"}\n",
        "BUCKET_NAME = \"[your-bucket-name]\" # @param {type:\"string\"}\n",
        "\n",
        "# Define AlloyDB connection parameters\n",
        "HOST = \"[your-alloydb-host-ip]\" # @param {type:\"string\"}\n",
        "DATABASE_NAME = \"[your-database-name]\" # @param {type:\"string\"}\n",
        "USER = \"[your-user]\" # @param {type:\"string\"}\n",
        "PASSWORD = \"[your-password]\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Buug0LTfbG"
      },
      "source": [
        "Create local authentication credentials for your user account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z63alSvKTfbG"
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8hf3qVZTfbG"
      },
      "source": [
        "Validate the google_ml_integration extension in AlloyDB (version 1.4.4 or later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gINJzS71TfbG"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "\n",
        "# Connection parameters\n",
        "conn_params = {\n",
        "    'host': HOST,\n",
        "    'database': DATABASE_NAME,\n",
        "    'user': USER,\n",
        "    'password': PASSWORD\n",
        "}\n",
        "\n",
        "# Establish connection\n",
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Validate extension\n",
        "query = \"\"\"\n",
        "select *\n",
        "    from pg_extension\n",
        "    where extname = 'google_ml_integration';\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "\n",
        "# Fetch result\n",
        "result = cursor.fetchone()\n",
        "print(f\"Extension validation result: {result}\")\n",
        "\n",
        "# Close connection\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wI43a85TfbH"
      },
      "source": [
        "Integrate AlloyDB with Vertx AI (https://cloud.google.com/alloydb/docs/ai/configure-vertex-ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate synthetic data"
      ],
      "metadata": {
        "id": "IvND_N6ZVbOq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItYvUNkpTfbH"
      },
      "source": [
        "Generate sample images for the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzvRIz1ITfbH"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from tqdm import tqdm\n",
        "\n",
        "#client = genai.Client(vertexai=True,project=\"mtoscano-dev-sandbox\",location=\"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True,project=PROJECT_ID,location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bEuvqvdTfbH",
        "outputId": "9a2ba920-0d52-4dbe-8740-7379d603200f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created output image using 1532822 bytes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Create images directory if it doesn't exist\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "# List of clothing items with colors\n",
        "prompts = [\n",
        "    \"red car\",\n",
        "    \"blue car\",\n",
        "    \"green car\",\n",
        "    \"yellow car\",\n",
        "    \"black car\",\n",
        "    \"white car\",\n",
        "    \"sports car\",\n",
        "    \"vintage car\",\n",
        "    \"convertible car\",\n",
        "    \"luxury car\",\n",
        "    \"small dog\",\n",
        "    \"big dog\",\n",
        "    \"fluffy dog\",\n",
        "    \"happy dog\",\n",
        "    \"sad dog\",\n",
        "    \"running dog\",\n",
        "    \"sleeping dog\",\n",
        "    \"coke bottle on a table\",\n",
        "    \"coke bottle in the snow\",\n",
        "    \"coke bottle on the beach\",\n",
        "    \"open suitcase\",\n",
        "    \"closed suitcase\",\n",
        "    \"leather suitcase\",\n",
        "    \"red suitcase\",\n",
        "    \"black suitcase\",\n",
        "    \"straw hat\",\n",
        "    \"baseball hat\",\n",
        "    \"winter hat\",\n",
        "    \"fancy hat\",\n",
        "    \"red hat\",\n",
        "    \"blue mobile phone\",\n",
        "    \"black mobile phone\",\n",
        "    \"broken mobile phone\",\n",
        "    \"old mobile phone\",\n",
        "    \"new mobile phone\",\n",
        "    \"wooden table\",\n",
        "    \"metal table\",\n",
        "    \"glass table\",\n",
        "    \"round table\",\n",
        "    \"square table\",\n",
        "    \"red table\",\n",
        "    \"blue table\",\n",
        "    \"green table\",\n",
        "    \"yellow table\",\n",
        "    \"black and white table\",\n",
        "    \"car in a city\",\n",
        "    \"dog in a park\",\n",
        "    \"coke bottles on a shelf\",\n",
        "    \"suitcase on a conveyor belt\",\n",
        "    \"hat on a head\",\n",
        "    \"mobile phone on a desk\",\n",
        "    \"table with food on it\"\n",
        "]\n",
        "\n",
        "# Generate output filenames\n",
        "output_files = [f\"images/item_{i+1}.png\" for i in range(len(prompts))]\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    image = client.models.generate_images(\n",
        "        model=\"imagen-4.0-generate-preview-05-20\",\n",
        "        prompt=prompt,\n",
        "    )\n",
        "    image.generated_images[0].image.save(output_files[i])\n",
        "print(f\"Created output image using {len(image.generated_images[0].image.image_bytes)} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cjiNMf4TfbH"
      },
      "source": [
        "Generate input images for the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rUYnAhQTfbH",
        "outputId": "5625cd5b-24e2-4a0f-e551-53458328e3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created output image using 1371299 bytes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create images directory if it doesn't exist\n",
        "os.makedirs(\"input_images\", exist_ok=True)\n",
        "\n",
        "# List of clothing items with colors\n",
        "prompts = [\n",
        "    \"A bottle of coke\",\n",
        "    \"wooden table\",\n",
        "    \"a dog playing with a ball\"\n",
        "]\n",
        "\n",
        "# Generate output filenames\n",
        "output_files = [f\"input_images/input_item_{i+1}.png\" for i in range(len(prompts))]\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    image = client.models.generate_images(\n",
        "        model=\"imagen-4.0-generate-preview-05-20\",\n",
        "        prompt=prompt,\n",
        "    )\n",
        "    image.generated_images[0].image.save(output_files[i])\n",
        "print(f\"Created output image using {len(image.generated_images[0].image.image_bytes)} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbM8RbKCTfbH"
      },
      "source": [
        "Create a GCS Bucket to store the catalog of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVP6RfH-TfbH"
      },
      "outputs": [],
      "source": [
        "# Create a new GCS bucket\n",
        "import os\n",
        "\n",
        "# Create the bucket using gsutil command\n",
        "bucket_creation_command = f\"gsutil mb -p {PROJECT_ID} -l {LOCATION} gs://{BUCKET_NAME}\"\n",
        "\n",
        "try:\n",
        "    # Execute the gsutil command\n",
        "    result = os.system(bucket_creation_command)\n",
        "    if result == 0:\n",
        "        print(f\"Successfully created bucket: gs://{BUCKET_NAME}\")\n",
        "    else:\n",
        "        print(\"Failed to create bucket\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating bucket: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QnbAzEBTfbH"
      },
      "source": [
        "Upload the sample images to the bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x70l_gyMTfbI"
      },
      "outputs": [],
      "source": [
        "# Upload images from local directory to GCS bucket\n",
        "import glob\n",
        "\n",
        "# Get list of images in the images directory\n",
        "image_files = glob.glob(\"images/*\")\n",
        "\n",
        "# Upload each image to GCS bucket\n",
        "for image_file in image_files:\n",
        "    # Get just the filename without path\n",
        "    filename = os.path.basename(image_file)\n",
        "\n",
        "    # Construct the GCS destination path\n",
        "    destination = f\"gs://{BUCKET_NAME}/images/{filename}\"\n",
        "\n",
        "    # Upload command\n",
        "    upload_command = f\"gsutil cp {image_file} {destination}\"\n",
        "\n",
        "    try:\n",
        "        # Execute the upload\n",
        "        result = os.system(upload_command)\n",
        "        if result == 0:\n",
        "            print(f\"Successfully uploaded {filename} to {destination}\")\n",
        "        else:\n",
        "            print(f\"Failed to upload {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading {filename}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gp3p_W0TfbI"
      },
      "source": [
        "Upload the input images to the bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWW4f9KSTfbI"
      },
      "outputs": [],
      "source": [
        "# Upload images from local directory to GCS bucket\n",
        "import glob\n",
        "\n",
        "# Get list of images in the images directory\n",
        "image_files = glob.glob(\"input_images/*\")\n",
        "\n",
        "# Upload each image to GCS bucket\n",
        "for image_file in image_files:\n",
        "    # Get just the filename without path\n",
        "    filename = os.path.basename(image_file)\n",
        "\n",
        "    # Construct the GCS destination path\n",
        "    destination = f\"gs://{BUCKET_NAME}/input_images/{filename}\"\n",
        "\n",
        "    # Upload command\n",
        "    upload_command = f\"gsutil cp {image_file} {destination}\"\n",
        "\n",
        "    try:\n",
        "        # Execute the upload\n",
        "        result = os.system(upload_command)\n",
        "        if result == 0:\n",
        "            print(f\"Successfully uploaded {filename} to {destination}\")\n",
        "        else:\n",
        "            print(f\"Failed to upload {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading {filename}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKt758e9TfbI"
      },
      "source": [
        "Create a table in AlloyDB to store the embeddings along with the metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvtVTIQbTfbI"
      },
      "outputs": [],
      "source": [
        "# Connect to AlloyDB and create table for storing image embeddings\n",
        "import psycopg2\n",
        "\n",
        "# Connection parameters\n",
        "conn_params = {\n",
        "    'host': HOST,\n",
        "    'database': DATABASE_NAME,\n",
        "    'user': USER,\n",
        "    'password': PASSWORD\n",
        "}\n",
        "\n",
        "try:\n",
        "    # Establish connection\n",
        "    conn = psycopg2.connect(**conn_params)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create vector extension if it doesn't exist\n",
        "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
        "\n",
        "    # Create table for storing image embeddings\n",
        "    create_table_query = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS images (\n",
        "        image_id SERIAL PRIMARY KEY,\n",
        "        image_uri TEXT NOT NULL,\n",
        "        embedding vector(1408)\n",
        "    );\n",
        "    \"\"\"\n",
        "    cursor.execute(create_table_query)\n",
        "\n",
        "    # Commit the changes\n",
        "    conn.commit()\n",
        "\n",
        "    print(\"Successfully created table 'images'\")\n",
        "\n",
        "    # Close connection\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the images embedding and load it to AlloyDB"
      ],
      "metadata": {
        "id": "s8gYcVJFV4hv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8GJjHVOTfbI"
      },
      "source": [
        "Load the images table with the embeddings and metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE2AWlwYTfbI"
      },
      "outputs": [],
      "source": [
        "# Connect to AlloyDB\n",
        "import psycopg2\n",
        "from google.cloud import storage\n",
        "\n",
        "conn_params = {\n",
        "    'host': HOST,\n",
        "    'database': DATABASE_NAME,\n",
        "    'user': USER,\n",
        "    'password': PASSWORD\n",
        "}\n",
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# List images in bucket\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(BUCKET_NAME)\n",
        "blobs = list(bucket.list_blobs(prefix='images/'))\n",
        "\n",
        "# Insert embeddings for each image\n",
        "for i, blob in enumerate(blobs, 1):\n",
        "    # Ensure we only process files with a valid content type to avoid errors\n",
        "    if not blob.content_type or not blob.content_type.startswith('image/'):\n",
        "        print(f\"Skipping non-image file: {blob.name}\")\n",
        "        continue\n",
        "\n",
        "    image_uri = f'gs://{BUCKET_NAME}/{blob.name}'\n",
        "\n",
        "    # CORRECT: Use ai.image_embedding and provide the mimetype\n",
        "    query = \"\"\"\n",
        "    SELECT ai.image_embedding(\n",
        "        model_id => 'multimodalembedding@001',\n",
        "        image => %s,\n",
        "        mimetype => %s\n",
        "    );\n",
        "    \"\"\"\n",
        "    # Pass both the URI and the blob's content type\n",
        "    cursor.execute(query, (image_uri, blob.content_type))\n",
        "    embedding = cursor.fetchone()[0]\n",
        "\n",
        "    # Insert into images table\n",
        "    insert_query = \"\"\"\n",
        "    INSERT INTO images (image_id, image_uri, embedding)\n",
        "    VALUES (%s, %s, %s);\n",
        "    \"\"\"\n",
        "    cursor.execute(insert_query, (i, image_uri, embedding))\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(f\"Successfully loaded embeddings for {len(blobs)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUV9xlFTfbI"
      },
      "source": [
        "Create a ScaNN index on the multimodal column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz-ir-X_TfbI"
      },
      "outputs": [],
      "source": [
        "# Connect to AlloyDB\n",
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        " # Create extension alloydb_scann if it doesn't exist\n",
        "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS alloydb_scann;\")\n",
        "\n",
        "# Create ScaNN index on multimodal column\n",
        "create_index_query = \"\"\"\n",
        "CREATE INDEX IF NOT EXISTS image_scann_idx\n",
        "ON images\n",
        "USING scann (embedding cosine)\n",
        "WITH (num_leaves = 5);\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(create_index_query)\n",
        "conn.commit()\n",
        "\n",
        "print(\"Successfully created ScaNN index on embedding column\")\n",
        "\n",
        "cursor.close()\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Similarity Search"
      ],
      "metadata": {
        "id": "v8XoN68tWE4L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezjZ2W6qTfbI"
      },
      "source": [
        "Perform a similarity search based on input images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWF-E9wrTfbI"
      },
      "source": [
        "Input Image 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlHZRotPTfbI"
      },
      "outputs": [],
      "source": [
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Generate embedding and perform similarity search in one query\n",
        "similarity_query = f\"\"\"\n",
        "WITH query_embedding AS (\n",
        "    SELECT ai.image_embedding(\n",
        "        model_id => 'multimodalembedding@001',\n",
        "        image => 'gs://{BUCKET_NAME}/input_images/input_item_1.png',\n",
        "        mimetype => 'image/png'\n",
        "    )::vector(1408) AS embedding\n",
        ")\n",
        "SELECT\n",
        "    image_id,\n",
        "    image_uri,\n",
        "    1 - (images.embedding <=> query_embedding.embedding) AS similarity_score\n",
        "FROM\n",
        "    images,\n",
        "    query_embedding\n",
        "ORDER BY\n",
        "    images.embedding <=> query_embedding.embedding ASC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "cursor.execute(similarity_query)\n",
        "results = cursor.fetchall()\n",
        "\n",
        "print(\"\\nTop 5 similar images:\")\n",
        "for row in results:\n",
        "    print(f\"ID: {row[0]}, Image URI: {row[1]}, Similarity Score: {row[2]:.4f}\")\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy3heZfvTfbI"
      },
      "source": [
        "Display the top 3 results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL9q_Zp-TfbI"
      },
      "outputs": [],
      "source": [
        "# Display the top 3 results\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.cloud import storage\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Create a figure with subplots for the top 3 results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Top 3 Similar Images', fontsize=16)\n",
        "\n",
        "for i in range(min(3, len(results))):\n",
        "    image_uri = results[i][1]\n",
        "    similarity_score = results[i][2]\n",
        "\n",
        "    # Parse the GCS URI to get bucket and blob name\n",
        "    # Format: gs://bucket-name/path/to/file\n",
        "    uri_parts = image_uri.replace('gs://', '').split('/', 1)\n",
        "    bucket_name = uri_parts[0]\n",
        "    blob_name = uri_parts[1]\n",
        "\n",
        "    # Download image from GCS\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    # Download image data\n",
        "    image_data = blob.download_as_bytes()\n",
        "\n",
        "    # Convert to PIL Image and then to array for matplotlib\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f'Rank {i+1}\\nSimilarity: {similarity_score:.4f}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show the query image for reference\n",
        "print(\"\\nQuery image:\")\n",
        "query_uri = f'gs://{BUCKET_NAME}/input_images/input_item_1.png'\n",
        "uri_parts = query_uri.replace('gs://', '').split('/', 1)\n",
        "bucket_name = uri_parts[0]\n",
        "blob_name = uri_parts[1]\n",
        "\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "query_image_data = blob.download_as_bytes()\n",
        "query_image = Image.open(io.BytesIO(query_image_data))\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(query_image)\n",
        "plt.title('Query Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzVOMw8PTfbI"
      },
      "source": [
        "Input Image 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pbvUlO8TfbI"
      },
      "outputs": [],
      "source": [
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Generate embedding and perform similarity search in one query\n",
        "similarity_query = f\"\"\"\n",
        "WITH query_embedding AS (\n",
        "    SELECT ai.image_embedding(\n",
        "        model_id => 'multimodalembedding@001',\n",
        "        image => 'gs://{BUCKET_NAME}/input_images/input_item_2.png',\n",
        "        mimetype => 'image/png'\n",
        "    )::vector(1408) AS embedding\n",
        ")\n",
        "SELECT\n",
        "    image_id,\n",
        "    image_uri,\n",
        "    1 - (images.embedding <=> query_embedding.embedding) AS similarity_score\n",
        "FROM\n",
        "    images,\n",
        "    query_embedding\n",
        "ORDER BY\n",
        "    images.embedding <=> query_embedding.embedding ASC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "cursor.execute(similarity_query)\n",
        "results = cursor.fetchall()\n",
        "\n",
        "print(\"\\nTop 5 similar images:\")\n",
        "for row in results:\n",
        "    print(f\"ID: {row[0]}, Image URI: {row[1]}, Similarity Score: {row[2]:.4f}\")\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UKosmLkTfbJ"
      },
      "source": [
        "Display the top 3 results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOiMGGk8TfbJ"
      },
      "outputs": [],
      "source": [
        "# Display the top 3 results\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.cloud import storage\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Create a figure with subplots for the top 3 results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Top 3 Similar Images', fontsize=16)\n",
        "\n",
        "for i in range(min(3, len(results))):\n",
        "    image_uri = results[i][1]\n",
        "    similarity_score = results[i][2]\n",
        "\n",
        "    # Parse the GCS URI to get bucket and blob name\n",
        "    # Format: gs://bucket-name/path/to/file\n",
        "    uri_parts = image_uri.replace('gs://', '').split('/', 1)\n",
        "    bucket_name = uri_parts[0]\n",
        "    blob_name = uri_parts[1]\n",
        "\n",
        "    # Download image from GCS\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    # Download image data\n",
        "    image_data = blob.download_as_bytes()\n",
        "\n",
        "    # Convert to PIL Image and then to array for matplotlib\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f'Rank {i+1}\\nSimilarity: {similarity_score:.4f}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show the query image for reference\n",
        "print(\"\\nQuery image:\")\n",
        "query_uri = f'gs://{BUCKET_NAME}/input_images/input_item_2.png'\n",
        "uri_parts = query_uri.replace('gs://', '').split('/', 1)\n",
        "bucket_name = uri_parts[0]\n",
        "blob_name = uri_parts[1]\n",
        "\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "query_image_data = blob.download_as_bytes()\n",
        "query_image = Image.open(io.BytesIO(query_image_data))\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(query_image)\n",
        "plt.title('Query Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV16STXNTfbJ"
      },
      "source": [
        "Input Image 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmHuwdDaTfbJ"
      },
      "outputs": [],
      "source": [
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Generate embedding and perform similarity search in one query\n",
        "similarity_query = f\"\"\"\n",
        "WITH query_embedding AS (\n",
        "    SELECT ai.image_embedding(\n",
        "        model_id => 'multimodalembedding@001',\n",
        "        image => 'gs://{BUCKET_NAME}/input_images/input_item_3.png',\n",
        "        mimetype => 'image/png'\n",
        "    )::vector(1408) AS embedding\n",
        ")\n",
        "SELECT\n",
        "    image_id,\n",
        "    image_uri,\n",
        "    1 - (images.embedding <=> query_embedding.embedding) AS similarity_score\n",
        "FROM\n",
        "    images,\n",
        "    query_embedding\n",
        "ORDER BY\n",
        "    images.embedding <=> query_embedding.embedding ASC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "cursor.execute(similarity_query)\n",
        "results = cursor.fetchall()\n",
        "\n",
        "print(\"\\nTop 5 similar images:\")\n",
        "for row in results:\n",
        "    print(f\"ID: {row[0]}, Image URI: {row[1]}, Similarity Score: {row[2]:.4f}\")\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P68l6bzNTfbJ"
      },
      "source": [
        "Display the top 3 results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpWmzyr8TfbJ"
      },
      "outputs": [],
      "source": [
        "# Display the top 3 results\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.cloud import storage\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Create a figure with subplots for the top 3 results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Top 3 Similar Images', fontsize=16)\n",
        "\n",
        "for i in range(min(3, len(results))):\n",
        "    image_uri = results[i][1]\n",
        "    similarity_score = results[i][2]\n",
        "\n",
        "    # Parse the GCS URI to get bucket and blob name\n",
        "    # Format: gs://bucket-name/path/to/file\n",
        "    uri_parts = image_uri.replace('gs://', '').split('/', 1)\n",
        "    bucket_name = uri_parts[0]\n",
        "    blob_name = uri_parts[1]\n",
        "\n",
        "    # Download image from GCS\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    # Download image data\n",
        "    image_data = blob.download_as_bytes()\n",
        "\n",
        "    # Convert to PIL Image and then to array for matplotlib\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f'Rank {i+1}\\nSimilarity: {similarity_score:.4f}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show the query image for reference\n",
        "print(\"\\nQuery image:\")\n",
        "query_uri = f'gs://{BUCKET_NAME}/input_images/input_item_3.png'\n",
        "uri_parts = query_uri.replace('gs://', '').split('/', 1)\n",
        "bucket_name = uri_parts[0]\n",
        "blob_name = uri_parts[1]\n",
        "\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "query_image_data = blob.download_as_bytes()\n",
        "query_image = Image.open(io.BytesIO(query_image_data))\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(query_image)\n",
        "plt.title('Query Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNxJINKTfbM"
      },
      "source": [
        "Perform a similarity search based on text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mICCgb3TfbM"
      },
      "outputs": [],
      "source": [
        "conn = psycopg2.connect(**conn_params)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Generate embedding and perform similarity search in one query\n",
        "similarity_query = f\"\"\"\n",
        "WITH query_embedding AS (\n",
        "    SELECT ai.text_embedding(\n",
        "        model_id => 'multimodalembedding@001',\n",
        "        content => 'A dog running in a park'\n",
        "    )::vector(1408) AS embedding\n",
        ")\n",
        "SELECT\n",
        "    image_id,\n",
        "    image_uri,\n",
        "    1 - (images.embedding <=> query_embedding.embedding) AS similarity_score\n",
        "FROM\n",
        "    images,\n",
        "    query_embedding\n",
        "ORDER BY\n",
        "    images.embedding <=> query_embedding.embedding ASC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "cursor.execute(similarity_query)\n",
        "results = cursor.fetchall()\n",
        "\n",
        "print(\"\\nTop 5 similar images:\")\n",
        "for row in results:\n",
        "    print(f\"ID: {row[0]}, Image URI: {row[1]}, Similarity Score: {row[2]:.4f}\")\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKbIFLIZTfbM"
      },
      "source": [
        "Display the top 3 results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py1ha58wTfbM"
      },
      "outputs": [],
      "source": [
        "# Display the top 3 results\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.cloud import storage\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Create a figure with subplots for the top 3 results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Top 3 Similar Images', fontsize=16)\n",
        "\n",
        "for i in range(min(3, len(results))):\n",
        "    image_uri = results[i][1]\n",
        "    similarity_score = results[i][2]\n",
        "\n",
        "    # Parse the GCS URI to get bucket and blob name\n",
        "    # Format: gs://bucket-name/path/to/file\n",
        "    uri_parts = image_uri.replace('gs://', '').split('/', 1)\n",
        "    bucket_name = uri_parts[0]\n",
        "    blob_name = uri_parts[1]\n",
        "\n",
        "    # Download image from GCS\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    # Download image data\n",
        "    image_data = blob.download_as_bytes()\n",
        "\n",
        "    # Convert to PIL Image and then to array for matplotlib\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f'Rank {i+1}\\nSimilarity: {similarity_score:.4f}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show the query text for reference\n",
        "print(\"\\nQuery text:\")\n",
        "query_text = f'A dog running in a park'\n",
        "print(query_text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "alloydb-multimodal-emb.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
